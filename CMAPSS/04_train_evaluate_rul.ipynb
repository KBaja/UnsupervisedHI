{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 11:13:39.356917: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, 'CMAPSS')\n",
    "import eval_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "params = {'legend.fontsize': 20,\n",
    "          'figure.figsize': (9,6),\n",
    "         'axes.labelsize': 20,\n",
    "         'axes.titlesize':20,\n",
    "         'xtick.labelsize':'xx-large',\n",
    "         'axes.linewidth' : 2,\n",
    "         'ytick.labelsize':'xx-large'}\n",
    "\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'eval_utils' from '/baja/CMAPSS_GITHUB/eval_utils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(eval_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(524644, 50, 14) (403697, 50, 14)\n"
     ]
    }
   ],
   "source": [
    "# Load data partial window\n",
    "PATH_IN = 'Data/N-CMAPSS'\n",
    "\n",
    "# Load training data\n",
    "X_windows = np.load(PATH_IN + '/X_windows.npy')\n",
    "U_windows = np.load(PATH_IN + '/U_windows.npy')\n",
    "C_windows = np.load(PATH_IN + '/C_windows.npy')\n",
    "W_windows = np.load(PATH_IN + '/W_windows.npy')\n",
    "Y_windows = np.load(PATH_IN + '/Y_windows.npy')\n",
    "\n",
    "# Load testing data\n",
    "X_windows_test = np.load(PATH_IN + '/X_windows_test.npy')\n",
    "U_windows_test = np.load(PATH_IN + '/U_windows_test.npy')\n",
    "C_windows_test = np.load(PATH_IN + '/C_windows_test.npy')\n",
    "W_windows_test = np.load(PATH_IN + '/W_windows_test.npy')\n",
    "Y_windows_test = np.load(PATH_IN + '/Y_windows_test.npy')\n",
    "\n",
    "print(X_windows.shape, X_windows_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_C = MinMaxScaler()\n",
    "C_windows_scaled = scaler_C.fit_transform(C_windows.reshape(-1,1))\n",
    "C_windows_test_scaled = scaler_C.transform(C_windows_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_windows_scaled = np.repeat(C_windows_scaled,X_windows.shape[1],axis = 1).reshape(-1,X_windows.shape[1],1)\n",
    "C_windows_test_scaled = np.repeat(C_windows_test_scaled,X_windows_test.shape[1],axis = 1).reshape(-1,X_windows_test.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(663, 1) (438, 1)\n"
     ]
    }
   ],
   "source": [
    "# Ground Truth HI\n",
    "PATH_IN = 'Data/N-CMAPSS'\n",
    "SOURCE = 'N-CMAPSS_DS03'\n",
    "\n",
    "ground_truth = pd.read_hdf(PATH_IN + \"/\" + SOURCE+'_cycle_test.h5', 'df')\n",
    "ground_truth2 = pd.read_hdf(PATH_IN + \"/\" + SOURCE+'_cycle_dev.h5', 'df')\n",
    "\n",
    "ground_truth = pd.concat([ground_truth,ground_truth2]).sort_values('unit').sort_index()\n",
    "\n",
    "\n",
    "g_units = ground_truth.unit.values\n",
    "g_his = ground_truth.HI.values\n",
    "\n",
    "g_cycles = []\n",
    "_, s_idx = np.unique(g_units, return_index=True)\n",
    "for i in g_units[np.sort(s_idx)]:\n",
    "    idx = np.ravel(g_units==i)\n",
    "    g_cycles.extend(np.arange(idx.sum())+1)\n",
    "g_cycles = np.array(g_cycles)\n",
    "\n",
    "train_idx = np.ravel(np.isin(g_units,[np.unique(U_windows)]))\n",
    "true_hi_train = g_his[train_idx].reshape(-1,1)\n",
    "true_hi_cycles = g_cycles[train_idx]\n",
    "true_hi_units = g_units[train_idx]\n",
    "\n",
    "\n",
    "test_idx = np.ravel(np.isin(g_units,[np.unique(U_windows_test)]))\n",
    "true_hi_test = g_his[test_idx].reshape(-1,1)\n",
    "true_hi_cycles_test = g_cycles[test_idx]\n",
    "true_hi_units_test = g_units[test_idx]\n",
    "print(true_hi_train.shape, true_hi_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Line RUL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RUL_model(t=64,\n",
    "              feature_X_in=14,\n",
    "              feature_W_in=4,\n",
    "              feature_H_in=1,\n",
    "              feature_out_size=1,\n",
    "              activation='relu',\n",
    "              filter=[10,10,1],\n",
    "              filter_size=10,\n",
    "              useH=True):\n",
    "    '''\n",
    "    RUL_model: Generates a model for predicting Remaining Useful Life (RUL).\n",
    "\n",
    "    Args:\n",
    "        t (int): Time steps.\n",
    "        feature_X_in (int): Number of features in input X.\n",
    "        feature_W_in (int): Number of features in input W.\n",
    "        feature_H_in (int): Number of features in input H.\n",
    "        feature_out_size (int): Number of features in the output.\n",
    "        activation (str): Activation function to use in the hidden layers.\n",
    "        filter (list): List containing the number of filters for each convolutional layer.\n",
    "        filter_size (int): Size of the convolutional filters.\n",
    "        useH (bool): Flag indicating whether to include H as input.\n",
    "                     If True, input will be [X, W, H, T].\n",
    "                     If False, input will be [X, W, T].\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.models.Model: RUL prediction model.\n",
    "\n",
    "    Note:\n",
    "        If useH is True, the model will accept input [X, W, H, T] and output Y.\n",
    "        If useH is False, the model will accept input [X, W, T] and output Y.\n",
    "    '''\n",
    "\n",
    "    # Define input layers for X, W, T, and H\n",
    "    x_in = tf.keras.layers.Input(shape=(t, feature_X_in), name=\"X_in\")\n",
    "    w_in = tf.keras.layers.Input(shape=(t, feature_W_in), name=\"W_in\")\n",
    "    t_in = tf.keras.layers.Input(shape=(t, 1), name=\"T_in\")\n",
    "    \n",
    "    # Concatenate input data based on the useH flag\n",
    "    if useH:\n",
    "        h_in = tf.keras.layers.Input(shape=(t, feature_H_in), name=\"H_in\")\n",
    "        x = tf.keras.layers.Concatenate(axis=-1)([x_in, w_in, h_in, t_in])\n",
    "    else:\n",
    "        x = tf.keras.layers.Concatenate(axis=-1)([x_in, w_in, t_in])\n",
    "      \n",
    "    # Apply convolutional layers\n",
    "    for i in filter:\n",
    "        x = tf.keras.layers.Conv1D(i, filter_size, 1, padding='same', activation=activation)(x)\n",
    "\n",
    "    # Flatten the output\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    \n",
    "    # Apply dense layers\n",
    "    y = tf.keras.layers.Dense(50, activation=activation)(x)\n",
    "    y = tf.keras.layers.Dense(feature_out_size, activation='linear')(y)\n",
    "\n",
    "    # Create the model with the appropriate inputs and outputs\n",
    "    if useH:\n",
    "        model = tf.keras.models.Model([x_in, w_in, t_in, h_in], y)\n",
    "    else:\n",
    "        model = tf.keras.models.Model([x_in, w_in, t_in], y)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 11:13:44.565160: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-01 11:13:50.620088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19914 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:3d:00.0, compute capability: 6.1\n",
      "2024-05-01 11:13:50.622309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22135 MB memory:  -> device: 1, name: Tesla P40, pci bus id: 0000:3e:00.0, compute capability: 6.1\n",
      "2024-05-01 11:13:50.623803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 140 MB memory:  -> device: 2, name: Tesla P40, pci bus id: 0000:60:00.0, compute capability: 6.1\n",
      "2024-05-01 11:13:50.626099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 22135 MB memory:  -> device: 3, name: Tesla P40, pci bus id: 0000:61:00.0, compute capability: 6.1\n",
      "2024-05-01 11:13:50.628061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 18496 MB memory:  -> device: 4, name: Tesla P40, pci bus id: 0000:b1:00.0, compute capability: 6.1\n",
      "2024-05-01 11:13:50.632581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 22135 MB memory:  -> device: 5, name: Tesla P40, pci bus id: 0000:b2:00.0, compute capability: 6.1\n",
      "2024-05-01 11:13:50.637423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 22135 MB memory:  -> device: 6, name: Tesla P40, pci bus id: 0000:da:00.0, compute capability: 6.1\n",
      "2024-05-01 11:13:50.641281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 22135 MB memory:  -> device: 7, name: Tesla P40, pci bus id: 0000:db:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "useH=False\n",
    "layers=  [10,10,1]\n",
    "Window_size = X_windows.shape[1]\n",
    "model = RUL_model(Window_size,filter = layers, useH = useH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN#:  0\n",
      "reset_weights\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 11:13:59.931474: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2024-05-01 11:14:00.739667: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x4bd4d9b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-01 11:14:00.739774: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla P40, Compute Capability 6.1\n",
      "2024-05-01 11:14:00.739802: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): Tesla P40, Compute Capability 6.1\n",
      "2024-05-01 11:14:00.739826: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): Tesla P40, Compute Capability 6.1\n",
      "2024-05-01 11:14:00.739848: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): Tesla P40, Compute Capability 6.1\n",
      "2024-05-01 11:14:00.739870: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (4): Tesla P40, Compute Capability 6.1\n",
      "2024-05-01 11:14:00.739891: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (5): Tesla P40, Compute Capability 6.1\n",
      "2024-05-01 11:14:00.739913: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (6): Tesla P40, Compute Capability 6.1\n",
      "2024-05-01 11:14:00.739935: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (7): Tesla P40, Compute Capability 6.1\n",
      "2024-05-01 11:14:00.773848: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-01 11:14:00.980643: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 113/1904 [>.............................] - ETA: 18s - loss: 21.0789"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43meval_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_and_evaluate_rul_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_windows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_windows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC_windows_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mU_windows\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_windows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_windows_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_windows_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC_windows_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mU_windows_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_windows_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43museH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43museH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m248\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mreset_weights\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/baja/CMAPSS_GITHUB/eval_utils.py:450\u001b[0m, in \u001b[0;36mtrain_and_evaluate_rul_model\u001b[0;34m(X_windows, W_windows, C_windows, U_windows, Y_windows, hi_train, X_windows_test, W_windows_test, C_windows_test, U_windows_test, Y_windows_test, hi_test, model, useH, runs, epochs, batch_size, learning_rate, reset_weights)\u001b[0m\n\u001b[1;32m    447\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mOPTIMIZER, loss\u001b[38;5;241m=\u001b[39mLOSS)\n\u001b[1;32m    449\u001b[0m callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \n\u001b[0;32m--> 450\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m#TRAIN RESULTS\u001b[39;00m\n\u001b[1;32m    454\u001b[0m y_temp \u001b[38;5;241m=\u001b[39m Y_windows[val_idx]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = eval_utils.train_and_evaluate_rul_model(X_windows, W_windows, C_windows_scaled, U_windows,Y_windows,_,X_windows_test, W_windows_test, C_windows_test_scaled, U_windows_test,Y_windows_test,_,\n",
    "                                             model,useH = useH, runs = 1, epochs = 30, batch_size=248,learning_rate = 0.001,reset_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_TR</th>\n",
       "      <th>MAPE_TR</th>\n",
       "      <th>RMSE_TR</th>\n",
       "      <th>MAE_TS</th>\n",
       "      <th>MAPE_TS</th>\n",
       "      <th>RMSE_TS</th>\n",
       "      <th>TIME</th>\n",
       "      <th>I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.688478</td>\n",
       "      <td>183.6308</td>\n",
       "      <td>29.074726</td>\n",
       "      <td>5.392739</td>\n",
       "      <td>22.195689</td>\n",
       "      <td>7.322837</td>\n",
       "      <td>179.745075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MAE_TR   MAPE_TR    RMSE_TR    MAE_TS    MAPE_TS   RMSE_TS        TIME  \\\n",
       "0  23.688478  183.6308  29.074726  5.392739  22.195689  7.322837  179.745075   \n",
       "\n",
       "   I  \n",
       "0  0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HI included RUL model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example using ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "useH=True\n",
    "layers=  [10,10,1]\n",
    "Window_size = X_windows.shape[1]\n",
    "model = RUL_model(Window_size,filter = layers, useH = useH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_train = eval_utils.expand_hi(C_windows,U_windows,true_hi_train,true_hi_cycles.reshape(-1,1),true_hi_units.reshape(-1,1))     \n",
    "hi_test = eval_utils.expand_hi(C_windows_test,U_windows_test,true_hi_test,true_hi_cycles_test,true_hi_units_test)\n",
    "\n",
    "hi_train = np.repeat(hi_train,X_windows.shape[1],axis = 1).reshape(-1,X_windows.shape[1],1)\n",
    "hi_test = np.repeat(hi_test,X_windows_test.shape[1],axis = 1).reshape(-1,X_windows_test.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN#:  0\n",
      "reset_weights\n",
      "Epoch 1/30\n",
      "1904/1904 [==============================] - 31s 14ms/step - loss: 5.5396 - val_loss: 4.5859\n",
      "Epoch 2/30\n",
      "1904/1904 [==============================] - 27s 13ms/step - loss: 4.5683 - val_loss: 4.5200\n",
      "Epoch 3/30\n",
      "1904/1904 [==============================] - 29s 14ms/step - loss: 4.4983 - val_loss: 4.5196\n",
      "Epoch 4/30\n",
      "1904/1904 [==============================] - 27s 13ms/step - loss: 4.4827 - val_loss: 4.4122\n",
      "Epoch 5/30\n",
      "1904/1904 [==============================] - 28s 13ms/step - loss: 4.4499 - val_loss: 4.3585\n",
      "Epoch 6/30\n",
      "1904/1904 [==============================] - 27s 13ms/step - loss: 4.4372 - val_loss: 4.5898\n",
      "Epoch 7/30\n",
      "1904/1904 [==============================] - 27s 13ms/step - loss: 4.4250 - val_loss: 4.3720\n",
      "Epoch 8/30\n",
      "1904/1904 [==============================] - 28s 13ms/step - loss: 4.3990 - val_loss: 4.4478\n",
      "Epoch 9/30\n",
      "1904/1904 [==============================] - 28s 13ms/step - loss: 4.3752 - val_loss: 4.5144\n",
      "Epoch 10/30\n",
      "1904/1904 [==============================] - 27s 13ms/step - loss: 4.3633 - val_loss: 4.3371\n",
      "Epoch 11/30\n",
      "1904/1904 [==============================] - 27s 13ms/step - loss: 4.3520 - val_loss: 4.3111\n",
      "Epoch 12/30\n",
      "1904/1904 [==============================] - 28s 13ms/step - loss: 4.3423 - val_loss: 4.3381\n",
      "Epoch 13/30\n",
      "1904/1904 [==============================] - 28s 13ms/step - loss: 4.3246 - val_loss: 4.2825\n",
      "Epoch 14/30\n",
      "1904/1904 [==============================] - 28s 13ms/step - loss: 4.2903 - val_loss: 4.2275\n",
      "Epoch 15/30\n",
      "1904/1904 [==============================] - 28s 13ms/step - loss: 4.2721 - val_loss: 4.3081\n",
      "Epoch 16/30\n",
      "1904/1904 [==============================] - 28s 13ms/step - loss: 4.2285 - val_loss: 4.1947\n",
      "Epoch 17/30\n",
      "1904/1904 [==============================] - 27s 13ms/step - loss: 4.2034 - val_loss: 4.1846\n",
      "Epoch 18/30\n",
      "1904/1904 [==============================] - 28s 13ms/step - loss: 4.1828 - val_loss: 4.3682\n",
      "Epoch 19/30\n",
      "1904/1904 [==============================] - 26s 13ms/step - loss: 4.1581 - val_loss: 4.1929\n",
      "Epoch 20/30\n",
      "1904/1904 [==============================] - 28s 13ms/step - loss: 4.1275 - val_loss: 4.1713\n",
      "Epoch 21/30\n",
      "1904/1904 [==============================] - 29s 14ms/step - loss: 4.1248 - val_loss: 4.0425\n",
      "Epoch 22/30\n",
      "1904/1904 [==============================] - 27s 13ms/step - loss: 4.0771 - val_loss: 4.1340\n",
      "Epoch 23/30\n",
      "1904/1904 [==============================] - 27s 13ms/step - loss: 4.0420 - val_loss: 4.3245\n",
      "Epoch 24/30\n",
      "1904/1904 [==============================] - 27s 13ms/step - loss: 4.0383 - val_loss: 4.0432\n",
      "Epoch 25/30\n",
      "1904/1904 [==============================] - 26s 13ms/step - loss: 4.0079 - val_loss: 3.9406\n",
      "Epoch 26/30\n",
      "1904/1904 [==============================] - 27s 13ms/step - loss: 3.9822 - val_loss: 3.8707\n",
      "Epoch 27/30\n",
      "1904/1904 [==============================] - 28s 14ms/step - loss: 3.9803 - val_loss: 4.1770\n",
      "Epoch 28/30\n",
      "1904/1904 [==============================] - 27s 13ms/step - loss: 3.9722 - val_loss: 3.8743\n",
      "Epoch 29/30\n",
      "1904/1904 [==============================] - 27s 13ms/step - loss: 3.9514 - val_loss: 3.8819\n",
      "Epoch 30/30\n",
      "1904/1904 [==============================] - 28s 13ms/step - loss: 3.9411 - val_loss: 4.0135\n",
      "212/212 [==============================] - 2s 6ms/step\n",
      "1628/1628 [==============================] - 10s 6ms/step\n",
      "{'MAE_TR': [23.490616], 'MAPE_TR': [185.79697608947754], 'RMSE_TR': [28.829237], 'MAE_TS': [4.533921], 'MAPE_TS': [12.306306511163712], 'RMSE_TS': [6.74911], 'TIME': [843.6295390129089], 'I': [0]}\n"
     ]
    }
   ],
   "source": [
    "result = eval_utils.train_and_evaluate_rul_model(X_windows, W_windows, C_windows_scaled, U_windows,Y_windows,hi_train,X_windows_test, W_windows_test, C_windows_test_scaled, U_windows_test,Y_windows_test,hi_test,\n",
    "                                             model,useH = useH, runs = 1, epochs = 30, batch_size=248,learning_rate = 0.001,reset_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_TR</th>\n",
       "      <th>MAPE_TR</th>\n",
       "      <th>RMSE_TR</th>\n",
       "      <th>MAE_TS</th>\n",
       "      <th>MAPE_TS</th>\n",
       "      <th>RMSE_TS</th>\n",
       "      <th>TIME</th>\n",
       "      <th>I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.490616</td>\n",
       "      <td>185.796976</td>\n",
       "      <td>28.829237</td>\n",
       "      <td>4.533921</td>\n",
       "      <td>12.306307</td>\n",
       "      <td>6.74911</td>\n",
       "      <td>843.629539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MAE_TR     MAPE_TR    RMSE_TR    MAE_TS    MAPE_TS  RMSE_TS        TIME  \\\n",
       "0  23.490616  185.796976  28.829237  4.533921  12.306307  6.74911  843.629539   \n",
       "\n",
       "   I  \n",
       "0  0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example using supervised learning HI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "useH=True\n",
    "layers=  [10,10,1]\n",
    "Window_size = X_windows.shape[1]\n",
    "model = RUL_model(Window_size,filter = layers, useH = useH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/baja/CMAPSS_GITHUB/eval_utils.py:62: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.array(result)\n"
     ]
    }
   ],
   "source": [
    "hi_train = np.load(PATH_IN + '/z_supervised_train.npy')\n",
    "hi_test = np.load(PATH_IN + '/z_supervised_test.npy')\n",
    "\n",
    "hi_train = eval_utils.expand_hi(C_windows,U_windows,hi_train,true_hi_cycles.reshape(-1,1),true_hi_units.reshape(-1,1))     \n",
    "hi_test = eval_utils.expand_hi(C_windows_test,U_windows_test,hi_test,true_hi_cycles_test,true_hi_units_test)\n",
    "\n",
    "hi_train = np.repeat(hi_train,X_windows.shape[1],axis = 1).reshape(-1,X_windows.shape[1],1)\n",
    "hi_test = np.repeat(hi_test,X_windows_test.shape[1],axis = 1).reshape(-1,X_windows_test.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN#:  0\n",
      "reset_weights\n",
      "Epoch 1/30\n",
      "1904/1904 [==============================] - 28s 12ms/step - loss: 5.6186 - val_loss: 4.5920\n",
      "Epoch 2/30\n",
      "1904/1904 [==============================] - 26s 12ms/step - loss: 4.6581 - val_loss: 4.6364\n",
      "Epoch 3/30\n",
      "1904/1904 [==============================] - 24s 12ms/step - loss: 4.5819 - val_loss: 4.5412\n",
      "Epoch 4/30\n",
      "1904/1904 [==============================] - 25s 12ms/step - loss: 4.5189 - val_loss: 4.5558\n",
      "Epoch 5/30\n",
      "1904/1904 [==============================] - 25s 12ms/step - loss: 4.4833 - val_loss: 4.3938\n",
      "Epoch 6/30\n",
      "1904/1904 [==============================] - 25s 12ms/step - loss: 4.4383 - val_loss: 4.3377\n",
      "Epoch 7/30\n",
      "1904/1904 [==============================] - 24s 12ms/step - loss: 4.4057 - val_loss: 4.2717\n",
      "Epoch 8/30\n",
      "1904/1904 [==============================] - 25s 12ms/step - loss: 4.3761 - val_loss: 4.3618\n",
      "Epoch 9/30\n",
      "1904/1904 [==============================] - 25s 12ms/step - loss: 4.3594 - val_loss: 4.3117\n",
      "Epoch 10/30\n",
      "1904/1904 [==============================] - 25s 12ms/step - loss: 4.3442 - val_loss: 4.2490\n",
      "Epoch 11/30\n",
      "1904/1904 [==============================] - 25s 12ms/step - loss: 4.3300 - val_loss: 4.2376\n",
      "Epoch 12/30\n",
      "1904/1904 [==============================] - 24s 12ms/step - loss: 4.3115 - val_loss: 4.2415\n",
      "Epoch 13/30\n",
      "1904/1904 [==============================] - 25s 12ms/step - loss: 4.2980 - val_loss: 4.2311\n",
      "Epoch 14/30\n",
      "1904/1904 [==============================] - 25s 12ms/step - loss: 4.2947 - val_loss: 4.3191\n",
      "Epoch 15/30\n",
      "1904/1904 [==============================] - 25s 12ms/step - loss: 4.2733 - val_loss: 4.2318\n",
      "Epoch 16/30\n",
      "1904/1904 [==============================] - 24s 12ms/step - loss: 4.2687 - val_loss: 4.1517\n",
      "Epoch 17/30\n",
      "1904/1904 [==============================] - 24s 12ms/step - loss: 4.2378 - val_loss: 4.3108\n",
      "Epoch 18/30\n",
      "1904/1904 [==============================] - 24s 12ms/step - loss: 4.2219 - val_loss: 4.1941\n",
      "Epoch 19/30\n",
      "1904/1904 [==============================] - 25s 12ms/step - loss: 4.1942 - val_loss: 4.1509\n",
      "Epoch 20/30\n",
      "1904/1904 [==============================] - 24s 12ms/step - loss: 4.1691 - val_loss: 4.0658\n",
      "Epoch 21/30\n",
      "1904/1904 [==============================] - 25s 12ms/step - loss: 4.1288 - val_loss: 4.1155\n",
      "Epoch 22/30\n",
      "1904/1904 [==============================] - 24s 12ms/step - loss: 4.1093 - val_loss: 4.0878\n",
      "Epoch 23/30\n",
      "1904/1904 [==============================] - 25s 12ms/step - loss: 4.0799 - val_loss: 4.1926\n",
      "Epoch 24/30\n",
      "1904/1904 [==============================] - 24s 12ms/step - loss: 4.0559 - val_loss: 3.9950\n",
      "Epoch 25/30\n",
      "1904/1904 [==============================] - 25s 12ms/step - loss: 4.0025 - val_loss: 3.9263\n",
      "Epoch 26/30\n",
      "1904/1904 [==============================] - 24s 12ms/step - loss: 3.9612 - val_loss: 3.9283\n",
      "Epoch 27/30\n",
      "1904/1904 [==============================] - 25s 12ms/step - loss: 3.9223 - val_loss: 3.8526\n",
      "Epoch 28/30\n",
      "1904/1904 [==============================] - 24s 12ms/step - loss: 3.8532 - val_loss: 3.8362\n",
      "Epoch 29/30\n",
      "1904/1904 [==============================] - 26s 12ms/step - loss: 3.8834 - val_loss: 3.7611\n",
      "Epoch 30/30\n",
      "1904/1904 [==============================] - 24s 12ms/step - loss: 3.8100 - val_loss: 3.8043\n",
      "212/212 [==============================] - 2s 6ms/step\n",
      "1628/1628 [==============================] - 10s 5ms/step\n",
      "{'MAE_TR': [23.806276], 'MAPE_TR': [186.9263768196106], 'RMSE_TR': [29.214224], 'MAE_TS': [4.5152493], 'MAPE_TS': [15.789946913719177], 'RMSE_TS': [6.3037457], 'TIME': [756.7721512317657], 'I': [0]}\n"
     ]
    }
   ],
   "source": [
    "result = eval_utils.train_and_evaluate_rul_model(X_windows, W_windows, C_windows_scaled, U_windows,Y_windows,hi_train,X_windows_test, W_windows_test, C_windows_test_scaled, U_windows_test,Y_windows_test,hi_test,\n",
    "                                             model,useH = useH, runs = 1, epochs = 30, batch_size=248,learning_rate = 0.001,reset_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_TR</th>\n",
       "      <th>MAPE_TR</th>\n",
       "      <th>RMSE_TR</th>\n",
       "      <th>MAE_TS</th>\n",
       "      <th>MAPE_TS</th>\n",
       "      <th>RMSE_TS</th>\n",
       "      <th>TIME</th>\n",
       "      <th>I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.806276</td>\n",
       "      <td>186.926377</td>\n",
       "      <td>29.214224</td>\n",
       "      <td>4.515249</td>\n",
       "      <td>15.789947</td>\n",
       "      <td>6.303746</td>\n",
       "      <td>756.772151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MAE_TR     MAPE_TR    RMSE_TR    MAE_TS    MAPE_TS   RMSE_TS  \\\n",
       "0  23.806276  186.926377  29.214224  4.515249  15.789947  6.303746   \n",
       "\n",
       "         TIME  I  \n",
       "0  756.772151  0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example using proposed constraint C HI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useH=True\n",
    "layers=  [10,10,1]\n",
    "Window_size = X_windows.shape[1]\n",
    "model = RUL_model(Window_size,filter = layers, useH = useH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_train = np.load(PATH_IN + '/z_constraint_c_train.npy')\n",
    "hi_test = np.load(PATH_IN + '/z_constraint_c_test.npy')\n",
    "\n",
    "hi_train = eval_utils.expand_hi(C_windows,U_windows,hi_train,true_hi_cycles.reshape(-1,1),true_hi_units.reshape(-1,1))     \n",
    "hi_test = eval_utils.expand_hi(C_windows_test,U_windows_test,hi_test,true_hi_cycles_test,true_hi_units_test)\n",
    "\n",
    "hi_train = np.repeat(hi_train,X_windows.shape[1],axis = 1).reshape(-1,X_windows.shape[1],1)\n",
    "hi_test = np.repeat(hi_test,X_windows_test.shape[1],axis = 1).reshape(-1,X_windows_test.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = eval_utils.train_and_evaluate_rul_model(X_windows, W_windows, C_windows_scaled, U_windows,Y_windows,hi_train,X_windows_test, W_windows_test, C_windows_test_scaled, U_windows_test,Y_windows_test,hi_test,\n",
    "                                             model,useH = useH, runs = 1, epochs = 30, batch_size=248,learning_rate = 0.001,reset_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
